# -*- coding: utf-8 -*-
"""Lung Cancer Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XBPSkyOYfBXRzN78ktpfTa0Y0Zh6nV0k
"""

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

from google.colab import drive
drive.mount('/content/drive')

train_folder = '/content/drive/MyDrive/Lung_Cancer/dataset-20250828T140847Z-1-001/dataset/train'
test_folder = '/content/drive/MyDrive/Lung_Cancer/dataset-20250828T140847Z-1-001/dataset/test'
validate_folder = '/content/drive/MyDrive/Lung_Cancer/dataset-20250828T140847Z-1-001/dataset/valid'

normal_folder = '/content/drive/MyDrive/Lung_Cancer/dataset-20250828T140847Z-1-001/dataset/test/normal'
adenocarcinoma_folder = '/content/drive/MyDrive/Lung_Cancer/dataset-20250828T140847Z-1-001/dataset/test/adenocarcinoma'
large_cell_carcinoma_folder = '/content/drive/MyDrive/Lung_Cancer/dataset-20250828T140847Z-1-001/dataset/test/large.cell.carcinoma'
squamous_cell_carcinoma_folder = '/content/drive/MyDrive/Lung_Cancer/dataset-20250828T140847Z-1-001/dataset/test/squamous.cell.carcinoma'

import warnings
warnings.filterwarnings('ignore')

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.decomposition import PCA
from sklearn.preprocessing import LabelEncoder

import tensorflow as tf
import tensorflow.keras
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, SpatialDropout2D, Activation, Lambda, Flatten, LSTM
from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D
from tensorflow.keras.optimizers import Adam, RMSprop
from tensorflow.keras import utils

print("Libraries Imported")

# Read data from the folders
IMAGE_SIZE = (350, 350)

print("Reading training images from:", train_folder)
print("Reading validation images from:", validate_folder)

train_datagen = ImageDataGenerator(rescale=1./255, horizontal_flip=True)
test_datagen = ImageDataGenerator(rescale=1./255)

batch_size = 8

train_generator = train_datagen.flow_from_directory(
    train_folder,
    target_size=IMAGE_SIZE,
    batch_size=batch_size,
    color_mode="rgb",
    class_mode='categorical'
)

validation_generator = test_datagen.flow_from_directory(
    test_folder,
    target_size=IMAGE_SIZE,
    batch_size=batch_size,
    color_mode="rgb",
    class_mode='categorical'
)

from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint

learning_rate_reduction = ReduceLROnPlateau(monitor='loss', patience=5, verbose=2, factor=0.5, min_lr=0.000001)
early_stops = EarlyStopping(monitor='loss', min_delta=0, patience=6, verbose=2, mode='auto')
checkpointer = ModelCheckpoint(filepath='best_model.weights.h5', verbose=2, save_best_only=True, save_weights_only=True)

OUTPUT_SIZE = 4

pretrained_model = tf.keras.applications.Xception(weights='imagenet', include_top=False, input_shape=[*IMAGE_SIZE, 3])
pretrained_model.trainable = False

model = Sequential()
model.add(pretrained_model)
model.add(GlobalAveragePooling2D())
model.add(Dense(OUTPUT_SIZE, activation='softmax'))

print("Pretrained model used:")
pretrained_model.summary()

print("Final model created:")
model.summary()

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

history = model.fit(
    train_generator,
    steps_per_epoch=25,
    epochs=5,
    callbacks=[learning_rate_reduction, early_stops, checkpointer],
    validation_data=validation_generator,
    validation_steps=20
)

print("Final training accuracy =", history.history['accuracy'][-1])
print("Final testing accuracy =", history.history['val_accuracy'][-1])

def display_training_curves(training, validation, title, subplot):
    if subplot % 10 == 1:
        plt.subplots(figsize=(10, 10), facecolor='#F0F0F0')
        plt.tight_layout()
    ax = plt.subplot(subplot)
    ax.set_facecolor('#F8F8F8')
    ax.plot(training)
    ax.plot(validation)
    ax.set_title('model ' + title)
    ax.set_ylabel(title)
    ax.set_xlabel('epoch')
    ax.legend(['train', 'valid.'])

display_training_curves(history.history['loss'], history.history['val_loss'], 'loss', 211)
display_training_curves(history.history['accuracy'], history.history['val_accuracy'], 'accuracy', 212)

model.save('/content/drive/MyDrive/Lung_Cancer/dataset-20250828T140847Z-1-001/dataset/trained_lung_cancer_model.h5')

from tensorflow.keras.preprocessing import image
import numpy as np

# Define a function to load and preprocess the image
def load_and_preprocess_image(img_path, target_size):
    img = image.load_img(img_path, target_size=target_size)
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array /= 255.0  # Rescale the image like the training images
    return img_array

# Load an image from your drive
img_path = '/content/drive/MyDrive/Lung_Cancer/dataset-20250828T140847Z-1-001/dataset/test/adenocarcinoma/000173 (7).png'
img = load_and_preprocess_image(img_path, IMAGE_SIZE)

# Make a prediction
predictions = model.predict(img)
predicted_class = np.argmax(predictions[0])

# Map the predicted class to the class label
class_labels = list(train_generator.class_indices.keys())
predicted_label = class_labels[predicted_class]

# Print the predicted class
print(f"The image belongs to class: {predicted_label}")

# Display the image
plt.imshow(image.load_img(img_path, target_size=IMAGE_SIZE))
plt.title(f"Predicted: {predicted_label}")
plt.axis('off')
plt.show()

from tensorflow.keras.preprocessing import image
import numpy as np

# Define a function to load and preprocess the image
def load_and_preprocess_image(img_path, target_size):
    img = image.load_img(img_path, target_size=target_size)
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array /= 255.0  # Rescale the image like the training images
    return img_array

# Load an image from your drive
img_path = '/content/drive/MyDrive/Lung_Cancer/dataset-20250828T140847Z-1-001/dataset/test/large.cell.carcinoma/000111 (2).png'
img = load_and_preprocess_image(img_path, IMAGE_SIZE)

# Make a prediction
predictions = model.predict(img)
predicted_class = np.argmax(predictions[0])

# Map the predicted class to the class label
class_labels = list(train_generator.class_indices.keys())
predicted_label = class_labels[predicted_class]

# Print the predicted class
print(f"The image belongs to class: {predicted_label}")

# Display the image
plt.imshow(image.load_img(img_path, target_size=IMAGE_SIZE))
plt.title(f"Predicted: {predicted_label}")
plt.axis('off')
plt.show()

from tensorflow.keras.preprocessing import image
import numpy as np

# Define a function to load and preprocess the image
def load_and_preprocess_image(img_path, target_size):
    img = image.load_img(img_path, target_size=target_size)
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array /= 255.0  # Rescale the image like the training images
    return img_array

# Load an image from your drive
img_path = '/content/drive/MyDrive/Lung_Cancer/dataset-20250828T140847Z-1-001/dataset/test/adenocarcinoma/000117.png'
img = load_and_preprocess_image(img_path, IMAGE_SIZE)

# Make a prediction
predictions = model.predict(img)
predicted_class = np.argmax(predictions[0])

# Map the predicted class to the class label
class_labels = list(train_generator.class_indices.keys())
predicted_label = class_labels[predicted_class]

# Print the predicted class
print(f"The image belongs to class: {predicted_label}")

# Display the image
plt.imshow(image.load_img(img_path, target_size=IMAGE_SIZE))
plt.title(f"Predicted: {predicted_label}")
plt.axis('off')
plt.show()

from tensorflow.keras.preprocessing import image
import numpy as np

# Define a function to load and preprocess the image
def load_and_preprocess_image(img_path, target_size):
    img = image.load_img(img_path, target_size=target_size)
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array /= 255.0  # Rescale the image like the training images
    return img_array

# Load an image from your drive
img_path = '/content/drive/MyDrive/Lung_Cancer/dataset-20250828T140847Z-1-001/dataset/test/normal/10 - Copy (2).png'
img = load_and_preprocess_image(img_path, IMAGE_SIZE)

# Make a prediction
predictions = model.predict(img)
predicted_class = np.argmax(predictions[0])

# Map the predicted class to the class label
class_labels = list(train_generator.class_indices.keys())
predicted_label = class_labels[predicted_class]

# Print the predicted class
print(f"The image belongs to class: {predicted_label}")

# Display the image
plt.imshow(image.load_img(img_path, target_size=IMAGE_SIZE))
plt.title(f"Predicted: {predicted_label}")
plt.axis('off')
plt.show()



from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

# Get the true labels and predictions for the test set
y_true = validation_generator.classes  # True labels
y_pred = []  # Predictions

# Iterate over the test set and make predictions
for i in range(validation_generator.samples // validation_generator.batch_size + 1):
    # added +1 to handle the last batch which may be smaller than the usual batch_size.
    # Use built-in next() function to get the next batch
    x, _ = next(validation_generator)  # Get the next batch of images
    pred = model.predict(x)  # Make predictions
    y_pred.extend(np.argmax(pred, axis=1))  # Get the predicted class labels

# Compute the confusion matrix
cm = confusion_matrix(y_true, y_pred)

# Plot the confusion matrix using seaborn
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=validation_generator.class_indices.keys(),
            yticklabels=validation_generator.class_indices.keys())
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix")
plt.show()



from tensorflow.keras.applications import ResNet50
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
from tensorflow.keras.models import Sequential
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# ... (Your existing code for data paths, IMAGE_SIZE, OUTPUT_SIZE, etc.) ...

# Data generators with augmentation
train_datagen = ImageDataGenerator(rescale=1./255, horizontal_flip=True)
test_datagen = ImageDataGenerator(rescale=1./255)

# Create data generators (for ResNet50 alone)
train_generator = train_datagen.flow_from_directory(
    train_folder,
    target_size=IMAGE_SIZE,
    batch_size=8,  # Adjust batch size as needed
    color_mode="rgb",
    class_mode='categorical'
)

validation_generator = test_datagen.flow_from_directory(
    test_folder,
    target_size=IMAGE_SIZE,
    batch_size=8,  # Adjust batch size as needed
    color_mode="rgb",
    class_mode='categorical'
)

# Load and freeze ResNet50
pretrained_model = ResNet50(weights='imagenet', include_top=False, input_shape=[*IMAGE_SIZE, 3])
pretrained_model.trainable = False

# Create the model
model = Sequential()
model.add(pretrained_model)
model.add(GlobalAveragePooling2D())
model.add(Dense(OUTPUT_SIZE, activation='softmax'))

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model
history = model.fit(
    train_generator,
    steps_per_epoch=20,  # Adjust steps_per_epoch as needed
    epochs=5,  # Adjust epochs as needed
    validation_data=validation_generator,
    validation_steps=20  # Adjust validation_steps as needed
)

# Show some output
print("Training completed after", len(history.history['loss']), "epochs.")
print("Final training loss:", history.history['loss'][-1])
print("Final training accuracy:", history.history['accuracy'][-1])
print("Final validation loss:", history.history['val_loss'][-1])
print("Final validation accuracy:", history.history['val_accuracy'][-1])

import matplotlib.pyplot as plt

# ... (Your existing code for model training) ...

# Plot training curves
plt.figure(figsize=(10, 5))

# Loss curve
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Loss Curve')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

# Accuracy curve
plt.subplot(1, 2, 2)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Accuracy Curve')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

plt.tight_layout()
plt.show()

from tensorflow.keras.preprocessing import image
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.applications.resnet50 import preprocess_input  # Use the correct preprocessing

# ✅ Use the same size as training
IMAGE_SIZE = (350, 350)

# Load and preprocess the image
img_path = '/content/drive/MyDrive/Lung_Cancer/dataset-20250828T140847Z-1-001/dataset/test/large.cell.carcinoma/000108.png'
img = image.load_img(img_path, target_size=IMAGE_SIZE)
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)
x = preprocess_input(x)  # Apply preprocessing

# Make a prediction
predictions = model.predict(x)
predicted_class = np.argmax(predictions[0])

# Map the predicted class to the class label
class_labels = list(train_generator.class_indices.keys())  # Assuming train_generator is defined
predicted_label = class_labels[predicted_class]

# Print the predicted class
print(f"The image belongs to class: {predicted_label}")

# Display the image
plt.imshow(img)
plt.title(f"Predicted: {predicted_label}")
plt.axis('off')
plt.show()



from tensorflow.keras.applications import ResNet50

# Load the ResNet50 model (without the classification layers)
pretrained_model = ResNet50(weights='imagenet', include_top=False)

# Print the model summary
pretrained_model.summary()

import matplotlib.pyplot as plt

# Assuming you have history_xception and history_resnet50 from training both models
# Replace these with the actual variable names if they are different

# Get accuracy values from history objects
# Replace 'history' with the actual variable name if you used a different one for Xception
xception_accuracy = history.history['accuracy']
# Assuming 'history' was used for ResNet50 as well, replace if different
resnet50_accuracy = history.history['accuracy']

# Create x-axis values (epochs)
epochs = range(1, len(xception_accuracy) + 1)

# Plot accuracy curves
plt.plot(epochs, xception_accuracy, label='Xception')
plt.plot(epochs, resnet50_accuracy, label='ResNet50')
plt.title('Model Accuracy Comparison')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

# ===== EVALUATION: Precision/Recall/F1, Confusion Matrix, AP/mAP, mAP@50, mAP@50-95 =====
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.metrics import (
    classification_report, confusion_matrix, average_precision_score,
    precision_score
)
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf

# 1) Build a NON-SHUFFLING generator for evaluation to keep order aligned
eval_datagen = ImageDataGenerator(rescale=1./255)
eval_generator = eval_datagen.flow_from_directory(
    test_folder,                  # or use validate_folder if you want validation metrics
    target_size=IMAGE_SIZE,
    batch_size=batch_size,
    color_mode="rgb",
    class_mode='categorical',
    shuffle=False                 # <-- IMPORTANT
)

# 2) Predict (let Keras infer steps; no ceil => no float error)
y_pred = model.predict(eval_generator, verbose=1)
y_pred_classes = np.argmax(y_pred, axis=1)

# 3) True labels and class names
y_true = eval_generator.classes
class_names = list(eval_generator.class_indices.keys())
num_classes = len(class_names)

# 4) Precision/Recall/F1 (per class + averages)
print(classification_report(y_true, y_pred_classes, target_names=class_names, digits=4))

# 5) Confusion Matrix
cm = confusion_matrix(y_true, y_pred_classes)
plt.figure(figsize=(8,6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=class_names, yticklabels=class_names)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

# 6) AP per class and mAP (PR-AUC across thresholds, one-vs-rest)
y_true_onehot = tf.keras.utils.to_categorical(y_true, num_classes=num_classes)

ap_per_class = []
valid_classes = []
for i, cname in enumerate(class_names):
    # Only compute AP if the class appears in the test set
    if y_true_onehot[:, i].sum() > 0:
        ap = average_precision_score(y_true_onehot[:, i], y_pred[:, i])
        ap_per_class.append(ap)
        valid_classes.append(cname)
        print(f"AP ({cname}): {ap:.4f}")
    else:
        print(f"AP ({cname}): N/A (no positive samples in test set)")

mAP_pr_auc = np.mean(ap_per_class) if ap_per_class else float('nan')
print(f"\nMean AP (PR-AUC over classes): {mAP_pr_auc:.4f}")

# 7) mAP@50 and mAP@50-95 (classification-style: mean PRECISION over thresholds)
#    Note: These are adapted for multi-class classification (no IoU here).
thresholds = np.linspace(0.50, 0.95, 10)
precisions_at_t = []

for t in thresholds:
    preds_bin = (y_pred >= t).astype(int)   # binarize per-class probabilities at threshold t
    per_class_precisions = []
    for i in range(num_classes):
        if y_true_onehot[:, i].sum() > 0:
            p = precision_score(y_true_onehot[:, i], preds_bin[:, i], zero_division=0)
            per_class_precisions.append(p)
    if per_class_precisions:
        precisions_at_t.append(np.mean(per_class_precisions))

mAP50 = precisions_at_t[0] if len(precisions_at_t) > 0 else float('nan')
mAP50_95 = np.mean(precisions_at_t) if len(precisions_at_t) > 0 else float('nan')

print(f"mAP@50 (mean precision @ prob ≥ 0.50): {mAP50:.4f}")
print(f"mAP@50-95 (mean precision averaged over 0.50..0.95): {mAP50_95:.4f}")

from sklearn.metrics import precision_score, recall_score, f1_score
import numpy as np
import tensorflow as tf

# ⚠️ Evaluation generator (no shuffle!)
eval_datagen = ImageDataGenerator(rescale=1./255)
eval_generator = eval_datagen.flow_from_directory(
    test_folder,                   # change to validation folder if needed
    target_size=IMAGE_SIZE,
    batch_size=batch_size,
    color_mode="rgb",
    class_mode='categorical',
    shuffle=False
)

# 1️⃣ Predictions
y_pred_probs = model.predict(eval_generator, verbose=1)
y_pred_classes = np.argmax(y_pred_probs, axis=1)
y_true = eval_generator.classes
num_classes = len(eval_generator.class_indices)

# 2️⃣ Overall Precision, Recall, F1
precision = precision_score(y_true, y_pred_classes, average="macro")
recall = recall_score(y_true, y_pred_classes, average="macro")
f1 = f1_score(y_true, y_pred_classes, average="macro")

# 3️⃣ mAP@50 (classification-style: mean precision at threshold 0.5)
y_true_onehot = tf.keras.utils.to_categorical(y_true, num_classes=num_classes)
preds_bin = (y_pred_probs >= 0.5).astype(int)

per_class_precisions = []
for i in range(num_classes):
    if y_true_onehot[:, i].sum() > 0:   # skip empty classes
        p = precision_score(y_true_onehot[:, i], preds_bin[:, i], zero_division=0)
        per_class_precisions.append(p)

map50 = np.mean(per_class_precisions) if per_class_precisions else float('nan')

# 4️⃣ Print results
print("\n=== Overall Evaluation Metrics ===")
print(f"Precision (macro): {precision:.4f}")
print(f"Recall (macro):    {recall:.4f}")
print(f"F1-score (macro):  {f1:.4f}")
print(f"mAP@50:            {map50:.4f}")